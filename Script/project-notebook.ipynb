{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tensorflow.python.keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import concatenate,Input,Dense,Conv2D,BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nimport tensorflow_datasets as tfds\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/tf-data/masterfile.csv')\n\nimg= data['0']\n\ndir = '../input/tf-data/Final_data/'\nimages  = [dir + addr for addr in img ]\n\nimg_arr = []\n\nfor n, image in tqdm(enumerate(images), total=len(images)):\n\n    image = cv2.imread(image)\n    img_arr.append(image)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_arr = np.array(img_arr)\nimg_arr.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(['0'],axis = 1 ,inplace = True)\nY_true = np.array(data)\n#Y_true = Y_true/224.0\n#Y_true = Y_true[:10000,:]\nY_true","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#img_arr = np.array(pd.read_csv('../input/sem-dataset/Dataset.csv'))\nimg_arr\ndef read_image_and_annotation(image, annotation):\n    '''\n    Casts the image and annotation to their expected data type and\n    normalizes the input image so that each pixel is in the range [-1, 1]\n\n    Args:\n     image (numpy array) -- input image\n     annotation (numpy array) -- ground truth label map\n\n    Returns:\n     preprocessed image-annotation pair\n    '''\n\n    image = tf.cast(image, dtype=tf.float32)\n    #image = tf.reshape(image, (image.shape[0], image.shape[1], 1,))\n    annotation = tf.cast(annotation, dtype=tf.int32)\n    image = image/255\n    \n\n    return image, annotation\n\n\ndef get_training_dataset(images, annos):\n    '''\n    Prepares shuffled batches of the training set.\n  \n    Args:\n      images (list of strings) -- paths to each image file in the train set\n      annos (list of strings) -- paths to each label map in the train set\n\n    Returns:\n      tf Dataset containing the preprocessed train set\n    '''\n    training_dataset = tf.data.Dataset.from_tensor_slices((images, annos))\n    training_dataset = training_dataset.map(read_image_and_annotation)\n\n    training_dataset = training_dataset.shuffle(1024)\n    training_dataset = training_dataset.batch(128)\n    training_dataset = training_dataset.repeat()\n\n\n    return training_dataset\n\ntrain_dataset = get_training_dataset(img_arr,Y_true)\n\ntrain_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.layers.Input(shape = (224,224,3,))\nb1 = tf.keras.layers.Conv2D(filters = 64 , kernel_size = (3,3),padding = 'same',activation = 'relu')(inputs)\nb1= tf.keras.layers.Conv2D(filters = 64 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b1)\nb1 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b1)\n\nb2 = tf.keras.layers.Conv2D(filters = 128 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b1)\nb2 = tf.keras.layers.Conv2D(filters = 128 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b2)\nb2 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b2)\n\nb3 = tf.keras.layers.Conv2D(filters = 256 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b2)\nb3 = tf.keras.layers.Conv2D(filters = 256 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b3)\nb3= tf.keras.layers.Conv2D(filters = 256 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b3)\nb3= tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b3)\n\nb4 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b3)\nb4 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b4)\nb4 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b4)\nb4 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b4)\n\nb5 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b4)\nb5 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b5)\nb5 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b5)\nb5 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b5)\n\nc6 = tf.keras.layers.Conv2D(4096,(7,7),activation  = 'relu',padding = 'same')(b5)\nc7 = tf.keras.layers.Conv2D(4096,(1,1),activation  = 'relu',padding = 'same')(c6)\ng1 = tf.keras.layers.GlobalAveragePooling2D()(c7)\nd1= tf.keras.layers.Dense(128,activation = 'relu')(g1)\nd2 = tf.keras.layers.Dense(2)(d1)\nmodel = tf.keras.Model(inputs = inputs,outputs = d2)\nmodel.compile(optimizer = 'adam',loss = 'mse',metrics = ['accuracy'])\nmodel.summary()\n#model.fit(images,Y,epochs = 30,callbacks=[tf.keras.callbacks.CSVLogger('training.csv')])\n\n# def block(x,n_convs,filters,kernel_size,activation,pool_size,pool_stride,block_name):\n\n#     for i in range(n_convs):\n#         x = tf.keras.layers.Conv2D(filters = filters , kernel_size = kernel_size,padding = 'same',activation = activation,name = f'{block_name}_conv{i+1}')(x)\n\n#     x = tf.keras.layers.MaxPool2D(pool_size=pool_size,strides = pool_stride,name = f'{block_name}_pool{i+1}')(x)\n#     return x\n\n\n# def main_model(image_inputs):\n\n#     b0 = image_inputs\n#     b0 = tf.image.grayscale_to_rgb(b0)\n\n    \n#     for i in range(2):\n#         x = tf.keras.layers.Conv2D(filters = 64 , kernel_size = (3,3),padding = 'same',activation = 'relu',name = f'block1_conv{i+1}')(x)\n\n#     x = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2),name = f'block1_pool{i+1}')(x)\n    \n#     for i in range(2):\n#         x = tf.keras.layers.Conv2D(filters = 128 , kernel_size = (3,3),padding = 'same',activation = 'relu',name = f'block2_conv{i+1}')(x)\n\n#     x = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2),name = f'block2_pool{i+1}')(x)\n\n#     for i in range(3):\n#         x = tf.keras.layers.Conv2D(filters = 256 , kernel_size = (3,3),padding = 'same',activation = 'relu',name = f'block3_conv{i+1}')(x)\n\n#     x = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2),name = f'block3_pool{i+1}')(x)\n\n#     for i in range(3):\n#         x = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu',name = f'block4_conv{i+1}')(x)\n\n#     x = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2),name = f'block4_pool{i+1}')(x)\n    \n#     for i in range(3):\n#         x = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu',name = f'block5_conv{i+1}')(x)\n\n#     x = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2),name = f'block5_pool{i+1}')(x)\n\n    \n\n#     model = tf.keras.Model(inputs = image_inputs , outputs = x)\n\n\n\n#     # Number of filters in the output layer\n  \n#     n  =4096\n\n#     c6 = tf.keras.layers.Conv2D(n,(7,7),activation  = 'relu',padding = 'same',name = 'conv6')(b5)\n\n#     c7 = tf.keras.layers.Conv2D(n,(1,1),activation  = 'relu',padding = 'same',name=  'conv7')(c6)\n\n#     g1 = tf.keras.layers.GlobalAveragePooling2D()(c7)\n\n#     d1 = tf.keras.layers.Dense(128,activation = 'relu')(g1)\n\n#     d2 = tf.keras.layers.Dense(2)(d1)\n\n#     return d2\n\n\n# def Coordinate_ext():\n\n#     inputs = tf.keras.layers.Input(shape = (224,224,1,))\n\n#     outputs  = main_model(inputs)\n#     model = tf.keras.Model(inputs = inputs,outputs = outputs)\n\n#     return model\n\n# model = Coordinate_ext()\n# model.summary()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images =  img_arr[:10000,:,:,:]\nimages.shape\nY = Y_true[:10000,:]\nY.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam',loss = 'mse',metrics = ['accuracy'])\nmodel.fit(images,Y,epochs = 10,steps_per_epoch = 128,callbacks=[tf.keras.callbacks.CSVLogger('training.csv')])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_huber.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def block(x,n_convs,filters,kernel_size,activation,pool_size,pool_stride,block_name):\n\n    for i in range(n_convs):\n        x = tf.keras.layers.Conv2D(filters = filters , kernel_size = kernel_size,padding = 'same',activation = activation,name = f'{block_name}_conv{i+1}')(x)\n\n    x = tf.keras.layers.MaxPool2D(pool_size=pool_size,strides = pool_stride,name = f'{block_name}_pool{i+1}')(x)\n    return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n     # define your model normally\n    inputs = tf.keras.layers.Input(shape = (224,224,3,))\n    b1 = tf.keras.layers.Conv2D(filters = 64 , kernel_size = (3,3),padding = 'same',activation = 'relu')(inputs)\n    b1= tf.keras.layers.Conv2D(filters = 64 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b1)\n    b1 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b1)\n\n    b2 = tf.keras.layers.Conv2D(filters = 128 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b1)\n    b2 = tf.keras.layers.Conv2D(filters = 128 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b2)\n    b2 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b2)\n\n    b3 = tf.keras.layers.Conv2D(filters = 256 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b2)\n    b3 = tf.keras.layers.Conv2D(filters = 256 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b3)\n    b3= tf.keras.layers.Conv2D(filters = 256 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b3)\n    b3= tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b3)\n\n    b4 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b3)\n    b4 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b4)\n    b4 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b4)\n    b4 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b4)\n\n    b5 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b4)\n    b5 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b5)\n    b5 = tf.keras.layers.Conv2D(filters = 512 , kernel_size = (3,3),padding = 'same',activation = 'relu')(b5)\n    b5 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = (2,2))(b5)\n\n    c6 = tf.keras.layers.Conv2D(4096,(7,7),activation  = 'relu',padding = 'same')(b5)\n    c7 = tf.keras.layers.Conv2D(4096,(1,1),activation  = 'relu',padding = 'same')(c6)\n    g1 = tf.keras.layers.GlobalAveragePooling2D()(c7)\n    d1= tf.keras.layers.Dense(128,activation = 'relu')(g1)\n    d2 = tf.keras.layers.Dense(2)(d1)\n    model = tf.keras.Model(inputs = inputs,outputs = d2)\n    model.compile(optimizer = 'adam',loss = 'mse',metrics = ['accuracy'])\n\n# train model normally\n\nmodel.fit(images,Y,epochs = 100,steps_per_epoch = 128,callbacks=[tf.keras.callbacks.CSVLogger('training.csv')])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img = cv2.imread('../input/tf-data/Final_data/002ae037be8b7b7a8605866296c2d0a1.png')\n# img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nimage = cv2.imread('../input/tf-data/Final_data/001d4373e64905a5804aa42a27bb8b83.png')\n\nprint(image.shape)\nimage = np.reshape(image,[1,224,224,3]) \nprediction = model.predict(image)\n[[x,y]] = prediction\n\nprint(f'X : {x}  , Y : {y}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('TPU_Trained_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}